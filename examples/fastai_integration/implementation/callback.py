# AUTOGENERATED! DO NOT EDIT! File to edit: . (unless otherwise specified).

__all__ = ['AcceleratorCallback']

# Cell
from fastcore.basics import store_attr
from fastai.callback.core import Callback
from fastai.distributed import DistributedDL
from fastai.optimizer import OptimWrapper

from accelerate import Accelerator

# Cell
class AcceleratorCallback(Callback):
    "A Callback that handles model, dataloader, and optimizer compatibility with Accelerate"
    def __init__(self, accelerator:Accelerator):
        store_attr()

    def before_fit(self):
        "Tie `self.accelerator` to the learner and prepare the model and optimizer"
        self.learn.accelerator = self.accelerator
        self.model = self.accelerator.prepare(self.learn.model)
        opt = self.accelerator.prepare_optimizer(self.learn.opt)
        # Does this maintain the layer groups?
        self.learn.opt = OptimWrapper(self.learn.model.parameters(), opt)
        self.learn.accelerator._optimizers.append(self.learn.opt)

    @staticmethod
    def _prepare_dataloader(dataloader, accelerator):
        "Prepares a single DistributedDL"
        return DistributedDL(
            dataloader,
            rank=accelerator.process_index,
            world_size=accelerator.num_processes
        )

    def before_train(self):
        if self.accelerator.num_processes > 1:
            self.learn.dl = self._prepare_dataloader(self.learn.dl, self.accelerator)

    def before_validate(self):
        if accelerator.num_processes > 1:
            self.learn.dl = self._prepare_dataloader(self.learn.dl, self.accelerator)